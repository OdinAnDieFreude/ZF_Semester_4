\section{Testing}
\enumstart
	\item Why does Software contain bugs?
	\enumstart
		\item Ability to predict the behaviour of complex software is limited
		\item We make mistakes
		\enumstart
			\item Unclear requirements, miscommunication
			\item Wrong assumptions
			\item Design errors
			\item Coding errors
		\enumend
	\enumend
	\item Increasing software reliability
	\enumstart
		\item Fault avoidance
		\enumstart
			\item Statically - without executing the program
			\item Developement methodologies
		\enumend
		\item Fault detection
		\enumstart
			\item Dynamically - executing the program
			\item Static code checkers
		\enumend
		\item Fault tolerance
		\enumstart
			\item Recover from faults at runtime
		\enumend
	\enumend
	\item Error
	\enumstart
		\item Deviation of the observed behaviour from the required behaviour
		\item Functional
		\item Non-functional
	\enumend
	\item Testing
	\enumstart
		\item Process of executing a program to find errors
		\item Testing can only show the presence of bugs, not their absence
	\enumend
	\item Test harness - Collection of software and test data to automate test execution
	\\ \includegraphics[width=0.5\textwidth]{img/test_harness.png}
	\enumstart
		\item Test driver - Applies test cases to UUT, including setup and cleanup
		\item Test stub - partial implementation that simulates the missing component by returning fake data
	\enumend
\enumend

\subsection{Unit testing}
\enumstart
	\item Testing of individual subsystems
	\item Goal: confirm that subsystem is correctly implemented and carries out the intended functionality
	\item To increase test coverage, test each method with several inputs
	\enumstart
		\item Cover valid and invalid inputs
		\item Cover different paths through the method
	\enumend
	\item Parameterized unit tests
	\enumstart
		\item Decouple test driver from test data
		\item Test data can be specified as values, ranges or random values
		\item Requires generic test oracles
	\enumend
	\item Rules
	\enumstart
		\item All tests should be fully automatic and check their own results
		\item Run tests frequently
		\item For each bug, write a unit test that exposes the bug
		\item Concentrate your tests on boundary conditions
		\item Test if exceptions are raised when things are expected to go wrong
		\item Better to write and run incomplete tests, than to not run tests at all
	\enumend
\enumend

\subsection{Integration testing}
\enumstart
	\item Testing of groups of subsystems
	\item Motivation: many faults result from the interaction of subsystems
	\item Goal: Test interfaces between subsystems
	\item Important: Unit test all classes in the subsystem before integration testing
	\item Strategies
	\enumstart
		\item Order in which the subsystems are selected for testing and integration
		\item Big-bang (non-incremental)
		\item Bottom-up
		\item Top-down
		\item Sandwich testing
		\item Continuous integration
	\enumend
\enumend

\subsection{System testing}
\includegraphics[width=0.5\textwidth]{img/system_testing.png}

\subsubsection{Functional testing}
\enumstart
	\item Testing functionality
	\item Treat system as a black box
	\item Test cases describe
	\enumstart
		\item Input data
		\item Flow of events
		\item Results to check
	\enumend
\enumend

\subsubsection{Non-functional testing}
\enumstart
	\item Stress testing (Explore limits of the system)
	\item Volume testing (Large amounts of data)
	\item Configuration testing (Various software and hardware configurations)
	\item Compatibility testing (e.g. backward compatibility)
	\item Security testing
	\item Timing testing
	\item Environmental testing (tolerance for heat, humidity, $\mathellipsis$)
	\item Recovery testing
	\item Usability testing
\enumend

\subsubsection{Acceptance testing}
\enumstart
	\item Demonstrate to customer
	\item Choice of test is made by clients
	\item Performed by the client
	\item Alpha-test / Beta-test
\enumend

\subsubsection{Installation testing}
\enumstart
	\item Test what users will do to install and set up the software
	\item Different environments
	\item Different configurations
\enumend

\subsubsection{Testing strategies}
\enumstart
	\item Exhaustive testing
	\item Random testing
	\item Functional-/black box testing
	\item Structural-/white box testing
\enumend

\subsection{Functional testing}
\enumstart
	\item Test suite should be complete w.r.t specification
	\item Test suite should be as precise as possible
	\item Treat the program as a black box
	\item Use functional specification as base for designing test cases
	\\ \includegraphics[width=0.5\textwidth]{img/functional_testing.png}
	\item Systematic functional testing
	\\ \includegraphics[width=0.5\textwidth]{img/systematic_functional_testing.png}
\enumend

\subsubsection{Functional specification}
\enumstart
	\item Describes technical requirement
	\item not how, but what it does
	\item informal or formal
\enumend

\subsubsection{Independently testable features}
\enumstart
	\item Decompose system into ITF
	\item ITF need not to correspond to classes or subsystems
\enumend

\subsubsection{Identifying representative values}
\enumstart
	\item Divide input into equivalence classes
	\item Chosing representatives for each equivalence class
	\enumstart
		\item Normal values
		\item Invalid values
		\item Special values (e.g. null, empty collection, $\mathellipsis$)
		\item Boundary values (Extreme values inside and outside of boundaries)
	\enumend
\enumend

\subsubsection{Test case specification}
\enumstart
	\item Combine representative values into test data
	\item Combinatorial testing (combine everything) $\rightarrow$ combinatorial explosion
	\enumstart
		\item Use semantic constraints to eliminate combinations
		\item Use domain knowledge to remove unnecessary combinations
	\enumend
	\item Pairwise testing
	\enumstart
		\item Bugs often depend on only a few variables
		\item Test only all pairs of input parameters
		\item Can generalize to $k$-way testing
		\item For $n$ parameters with $d$ values each, number of tests grows log in $n$ and quadratic in $d$
	\enumend
\enumend

\subsubsection{Model-based testing}
\enumstart
	\item Goal: derive test-cases from models
	\item Benefits:
	\enumstart
		\item Compare actual behaviour to modeled behaviour
		\item Measure coverage w.r.t model
		\item (Partly) automate test case generation
	\enumend
	\item Models
	\enumstart
		\item Structural model
		\enumstart
			\item Contains the main concepts manipulated by the system, their properties and relationships
			\item Relevant information
			\enumstart
				\item Classes and attributes
				\item Subtypes
				\item Associations and multiplicities
			\enumend
		\enumend
		\item Behavioral model
		\enumstart
			\item Sequence diagrams (usefull for integration testing)
			\item State diagrams (states $\rightarrow$ equivalence classes)
			\enumstart
				\item State coverage
				\item Transition coverage
			\enumend
		\enumend
		\item Decision structures
		\item Grammars
		\enumstart
			\item Complex inputs can often be described by a (contextfree) grammar
			\item Input of varying and unbounded size
			\item Input with recursive structure
			\item Test cases: Strings generated by the grammar
			\item Coverage criteria
			\enumstart
				\item Production coverage - each production must be used to create a t least one test case
				\item Boundary condition - generate for all productions: Min+1, Min, Max, Max-1
			\enumend
		\enumend
	\enumend
\enumend

\subsection{Structural testing}

\subsubsection{Control flow testing}
\enumstart
	\item Idea: Cover as many different flows of control as possible
	\item Control flow graph
	\enumstart
		\item Basic blocks as Nodes
		\item Flow of control as Edges
	\enumend
\enumend

\subsubsection{Basic Blocks}
\enumstart
	\item Sequence of statements with exactly one entry-point and one exit-point
	\item Whenever the first instruction is executed, the rest is executed once and in order
\enumend

\subsubsection{Intraprocedural control flow graph (CFG)}
\enumstart
	\item A CFG of a method is
	\enumstart
		\item A graph $(N, E)$
		\item $N$ contains the basic blocks of the method
		\item $E$ contains
		\enumstart
			\item edges $(a, b, c)$ where
			\enumstart
				\item the control flow goes from $a$ to $b$
				\item under the condition that $c$ holds
			\enumend
			\item an entry $(entry, a, true)$ to the first basic block
			\item edges $(b, exit, true)$ for each $b$ that ends with a return statement
		\enumend
	\enumend
\enumend

\subsubsection{Statement coverage}
\enumstart
	\item $\text{Statement coverage} = \frac{\text{Number of executed Statements}}{\text{Total number of Statements}}$
	\item Can also be defined on basic blocks
\enumend

\subsubsection{Branch coverage}
\enumstart
	\item An edge $(a,b,c)$ is a branch iff there is another edge $(a,b',c')$ with $b \ne b'$
	\item $\text{Branch coverage} = \frac{\text{Number of executed branches}}{\text{Total number of branches}}$
	\item If code has no branches, branch coverage is defined to be 100\%
	\item Complete branch coverage leads to complete statement coverage
	\item At least $n$\% branch coverage does not imply at least $n$\% statement coverage
	\item Most widely used in industry
\enumend

\subsubsection{Path coverage}
\enumstart
	\item A path is a sequence of nodes $n_1, \mathellipsis, n_k$ such that
	\enumstart
		\item $n_1$ is an entry point
		\item $n_k$ is an exit
		\item There is an edge $(n_i, n_{i+1}, c)$ for all $1 \le i \le k-1$
	\enumend
	\item $\text{Path coverage} = \frac{\text{Number of executed paths}}{\text{Total number of paths}}$
	\item Complete path coverage leads to complete branch coverage
	\item At least $n$\% branch coverage does not imply at least $n$\% branch coverage
	\item Complete path coverage is not feasible for loops (infinity amount of paths)
\enumend

\subsubsection{Loop coverage}
\enumstart
	\item $\text{Loop coverage} = \frac{\text{Number of executed loops with 0, 1 and more iterations}}{\text{Total number of loops * 3}}$
	\item Often combined with other adequacy criteria
\enumend

\subsubsection{Data flow testing}
\enumstart
	\item Test the paths, where a computation in one part of the path affects the computations of another
	\item Complements control flow testing
\enumend

\subsubsection{Variable definition}
\enumstart
	\item A variable definition for $v$ is a basic block, that assigns to $v$
\enumend

\subsubsection{Variable use}
\enumstart
	\item A variable use for $v$ is a basic block, that reads the value of $v$
\enumend

\subsubsection{Definition-Clear path}
\enumstart
	\item A path $n_1, \mathellipsis, n_k$ in the CFG, where
	\enumstart
		\item $n_1$ is a variable definition for $v$
		\item $n_k$ is a variable use for $v$
		\item $n_2, \mathellipsis, n_{k}$ are no variable definitions (except for $n_k$ iff it defines after the use)
	\enumend
	\item 
\enumend

\subsubsection{Definition-Use Pair}
\enumstart
	\item A pair $(a,b)$ is a DU-pair iff $a, n_1, \mathellipsis, n_k, b$ is a definition-Clear path
\enumend

\subsubsection{DU-Pairs coverage}
\enumstart
	\item $\text{DU-Pairs coverage} = \frac{\text{Number of executed DU-Pairs}}{\text{Total number of DU-Pairs}}$
\enumend

\subsubsection{Determing all DU-Pairs}
\enumstart
	\item Computed using a static reaching-definitions analysis
	\\ \includegraphics[width=0.5\textwidth]{img/reaching_definitions.png}
	\item DU-Pairs = $\{(d,u) | u$ \text{is a variable use for} $v$ \text{ and }$v_d \in Reach(u)\}$
\enumend

